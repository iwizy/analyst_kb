# Сложность и O-нотация

> Глоссарий терминов и сокращений: [Открыть](../glossary.md)


Сложность алгоритма показывает, как меняются затраты времени и памяти при росте входных данных.

## Уровни сложности

### Базовый

- различать Big-O, Big-Omega, Big-Theta;
- оценивать порядок роста алгоритма;
- понимать разницу между временем и памятью.

### Средний

- анализировать лучший/средний/худший случай;
- учитывать амортизированную сложность;
- связывать сложность с продуктовым SLA.

### Продвинутый

- сравнивать сложность с учетом констант, кэша и профиля данных;
- оценивать алгоритмы в batch/streaming/real-time условиях;
- принимать инженерные решения с учетом worst-case рисков.

## Что такое Big-O, Big-Omega, Big-Theta

| Нотация | Смысл | Пример |
| --- | --- | --- |
| Big-O | верхняя граница роста | бинарный поиск O(log n) |
| Big-Omega | нижняя граница роста | сравнивающая сортировка Omega(n log n) |
| Big-Theta | точная асимптотика | обход массива Theta(n) |

## Типовые классы сложности

| Класс | Описание | Пример |
| --- | --- | --- |
| O(1) | константная | доступ по индексу массива |
| O(log n) | логарифмическая | бинарный поиск |
| O(n) | линейная | поиск max в массиве |
| O(n log n) | квази-линейная | merge sort, heap sort |
| O(n^2) | квадратичная | bubble sort, вложенные циклы |
| O(2^n) | экспоненциальная | полный перебор подмножеств |
| O(n!) | факториальная | полный перебор перестановок |

## Пример 1: нахождение максимума

```text
function find_max(arr):
  max_value = arr[0]
  for x in arr:
    if x > max_value:
      max_value = x
  return max_value
```

- Время: `O(n)`
- Память: `O(1)`

## Пример 2: линейный поиск

```text
function linear_search(arr, target):
  for i from 0 to len(arr)-1:
    if arr[i] == target:
      return i
  return -1
```

- Лучший случай: `O(1)` (первый элемент)
- Худший случай: `O(n)`
- Память: `O(1)`

## Как выбирать алгоритм под задачу

1. Зафиксируйте ограничения: `n`, latency, память.
2. Уточните свойства данных: отсортированы ли, есть ли дубликаты.
3. Сравните худший и средний случай.
4. Учтите частоту операций (поиск vs вставка/удаление).
5. Проверьте на representative dataset.

## Плюсы и минусы асимптотического анализа

| Плюсы | Минусы |
| --- | --- |
| дает единый язык сравнения | игнорирует константы и особенности железа |
| помогает предсказать масштабирование | не заменяет профилирование |
| полезен для архитектурных решений | может быть неверно применен без контекста данных |

## Типичные ошибки

- оценка только лучшего случая;
- сравнение алгоритмов без учета входного профиля;
- игнорирование memory complexity;
- слепое следование Big-O без benchmark.
## Задачи для самопроверки

1. Оцените сложность алгоритма, который делает два последовательных прохода по массиву.
2. Сравните `O(n log n)` и `O(n^2)` для `n = 100`, `n = 10_000`.
3. Для собственного кейса сформулируйте приемлемый верхний предел сложности.

## Источники и дальнейшее изучение

- CLRS, главы 2-4.
- Knuth, *The Art of Computer Programming*.
- MIT OCW: asymptotic analysis lectures.
