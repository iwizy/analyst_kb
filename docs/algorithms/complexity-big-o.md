# Сложность алгоритмов и O-нотация

Big O описывает рост затрат алгоритма при увеличении объема входных данных. Для аналитика это база для аргументации нефункциональных требований и архитектурных решений.

## Ключевые классы сложности

| Класс | Интерпретация | Пример |
| --- | --- | --- |
| `O(1)` | постоянное время | доступ по ключу в hash table (в среднем) |
| `O(log n)` | медленный рост | бинарный поиск |
| `O(n)` | линейный рост | один проход по списку |
| `O(n log n)` | эффективная сортировка | merge/heap/quick (в среднем) |
| `O(n^2)` | квадратичный рост | двойной цикл, bubble sort |
| `O(2^n)` / `O(n!)` | взрывной рост | полный перебор вариантов |

## Как оценивать алгоритм на практике

1. Определите доминирующую операцию (сравнение, lookup, insert).
1. Подсчитайте, сколько раз она выполняется при росте `n`.
1. Уберите константы и младшие члены.
1. Сравните альтернативы по времени и памяти.

## Важные уточнения

- Big O не учитывает константы, но в малых данных они могут быть важны.
- В проде всегда смотрят не только асимптотику, но и профилирование.
- Есть лучший, средний и худший случаи - фиксируйте, какой важен для SLA.

## Пример выбора

Задача: многоразовый поиск клиента по `customer_id`.

- Список + линейный поиск: `O(n)` каждый запрос.
- Хеш-таблица: `O(1)` в среднем.

Если запросов много, хеш-таблица резко снижает суммарную задержку.

## Типовые ошибки

- сравнивать алгоритмы без одинаковых входных условий;
- игнорировать худший случай при критичных SLA;
- оптимизировать редкую операцию вместо частой.

## Самопроверка

1. Почему `O(log n)` почти всегда лучше `O(n)` на больших выборках?
1. В каком случае `O(n log n)` может быть практичнее `O(n)`?
1. Как учитывать память при сравнении двух алгоритмов?
